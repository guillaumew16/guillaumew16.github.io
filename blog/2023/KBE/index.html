<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Making sense of the Kolmogorov backward equation (for diffusion processes) | Guillaume Wang </title> <meta name="author" content="Guillaume Wang"> <meta name="description" content="Machine learning theory, applied mathematics, etc. "> <meta name="keywords" content="machine learning, mathematics, optimization, optimal transport"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?aa2fd88e52df6cb3146c60000125eab2"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://guillaumew16.github.io/blog/2023/KBE/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Guillaume</span> Wang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Research blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <link rel="stylesheet" href="/assets/css/post_custom.css?5be8581675d5ca56cf9d2d53c35cbaf6"> <div class="post"> <header class="post-header"> <h1 class="post-title">Making sense of the Kolmogorov backward equation (for diffusion processes) </h1> <p class="post-meta"> Created in August 26, 2023 by Guillaume Wang </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/math"> <i class="fa-solid fa-tag fa-sm"></i> math</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>I once struggled quite a lot to wrap my head around convex duality. I wouldn’t go as far as to say I understand it now, but at least I got used to it, and I feel like it “makes sense”. However I was recently again in a similar situation, with diffusion processes and specifically the Kolmogorov backward equation: I could follow its derivation on a formal level, but I had a hard time understanding what it means. In this post I write down some calculations that were somewhat helpful to me, to make sense of it.</p> </blockquote> <p>Most of the content here is taken or extrapolated from the recent book [1, Chapters 3 and 8], which I find strikes a nice balance between concision and clarity. A more rigorous and detailed presentation can be found in the also very nice book [2, Chapters 6 and 10]. Unlike for previous posts, I don’t include a summary of the relevant background; let me just say that in my experience, formal manipulations of SDEs make intuitive sense even without knowing any of the theory behind, except for Ito’s formula which is not obvious at first (but easy to look up, e.g. in <a href="https://www.youtube.com/watch?v=kQTi2ckWufg" rel="external nofollow noopener" target="_blank">this 3-minute YouTube video</a>).</p> <h4 id="notation">Notation.</h4> <p>”\(\nabla\)” denotes gradient and “\(\nabla \cdot\)” denotes divergence. For two matrices \(A, B \in \mathbb{R}^{d \times d}\), \(A:B = \sum_{ij} A_{ij} B_{ij} = \mathop{\mathrm{Tr}}(A B^\top)\). For a matrix field \(A: \mathbb{R}^d \to \mathbb{R}^{d \times d}\), \(\nabla^2 : A = \sum_{ij} \partial_i \partial_j A_{ij}\).</p> <p>For \(\varphi \in C_b(\mathbb{R}^d)\) and \(\mu \in \mathcal{M}(\mathbb{R}^d)\), we write indifferently \(\left\langle \mu, \varphi \right\rangle\) or \(\mu \cdot \varphi\) or \(\mu \varphi\) to denote \(\int_{\mathbb{R}^d} \varphi d\mu\). For a transition kernel \(P\) and a probability distribution \(\mu\), we may write \(\mu P\) for \(P^* \mu\). For a finite-state time-homogeneous Markov chain for example, this means that we can represent \(P\) as a square matrix with \(P_{ij} = \mathbb{P}(X_{k+1} = j | X_k = i)\), probability distributions as row vectors, and test functions as column vectors; in particular, \(\mu P^k \varphi = \mathbb{E}_{X_0 \sim \mu}[\varphi(X_k)]\).</p> <p>We will use the terms “diffusion process” and “solution of a SDE” interchangeably, following the remark of [1, Sec. 7.3]. This is justified more rigorously by [2, Sec. 9.7-9.9].</p> <h1 id="sec:setting">Setting and statement of the equations</h1> <p>Consider a particle whose spatial position \(X_t \in \mathbb{R}^d\) evolves in time according to the SDE</p> \[dX_t = b_t(X_t) + \sigma_t(X_t) dW_t.\] <p>I will ignore regularity issues, so here \(b\) and \(\sigma\) are nice smooth functions, say, with uniformly bounded derivatives of all orders.</p> <h4 id="the-forward-equation">The forward equation.</h4> <p>If \(X_0 \sim \mu_0\), then \(\mu_t = \mathrm{Law}(X_t)\) is a distributional solution of the PDE, called <em>Fokker-Planck equation</em> or <em>Kolmogorov Forward Equation</em>,</p> \[\label{eq:setting:FP_KFE} \tag{KFE} \partial_t \mu_t = -\nabla \cdot [b_t \mu_t] + \frac{1}{2} \nabla^2 : [\sigma_t \sigma_t^\top \mu_t] ~~~~\text{with initial condition}~~~~ \mu_0.\] <div class="proof" text="sketched"> <p>By definition of distributional solutions, it suffices to check that for any \(\varphi \in C^\infty_c(\mathbb{R}^d)\) it holds</p> \[\frac{d}{dt} \mathbb{E}\varphi(X_t) = \nabla \varphi(X_t) \cdot b_t(X_t) + \frac{1}{2} \nabla^2 \varphi(X_t) : \sigma_t(X_t) \sigma_t(X_t)^\top,\] <p>which can be shown straightforwardly by computing \(d \varphi(X_t)\) thanks to Ito’s formula and by taking expectations.</p> </div> <h4 id="the-backward-equation">The backward equation.</h4> <p>For any fixed test function \(\varphi \in C^\infty_c\) and final time \(t\), let</p> \[\forall s \leq t, \forall y \in \mathbb{R}^d,~ u(y, s) = \mathbb{E}[\varphi(X_t) | X_s = y].\] <p>Then \(u(y,s)\) is the unique solution to the PDE, called Kolmogorov Backward Equation,</p> \[\label{eq:setting:KBE} \tag{KBE} -\partial_s u_s = \nabla u_s \cdot b_s + \frac{1}{2} \nabla^2 u_s : \sigma_s \sigma_s^\top ~~~~\text{with final condition}~~~~ u(\cdot, t) = \varphi(\cdot).\] <div class="proof" text="informal"> <p>Let us check that \(u(y, s) := \mathbb{E}[\varphi(X_t) | X_s = y]\) satisfies \(\eqref{eq:setting:KBE}\). The final condition \(u(\cdot, t) = \varphi(\cdot)\) is immediate from the definition of \(u\). Next consider the process \(u(X_\tau, \tau)\) for \(0 \leq \tau \leq t\), which by Ito’s formula evolves as</p> \[du(X_\tau, \tau) = \left[ \partial_s u(X_\tau, \tau) + \partial_y u(X_\tau, \tau) \cdot b_\tau(X_\tau) + \frac{1}{2} \partial_{yy}^2 u(X_\tau, \tau) : \sigma_\tau(X_\tau) \sigma_\tau(X_\tau)^\top \right] d\tau + [...] dW_\tau.\] <p>Here \(\partial_s u\) denotes partial derivative of \(u\) w.r.t. its second variable, and \(\partial_y\), \(\partial_{yy}^2\) are its partial derivatives w.r.t. its first variable. Integrating over \(\tau \in [s, r]\) for some fixed \(s\) and \(r \leq t\), and taking expectations conditioned on \(X_s = y\) which we denote as \(\mathbb{E}^{y,s} = \mathbb{E}[\cdot | X_s=y]\), we have</p> \[\mathbb{E}^{y,s}[ u(X_r, r) - u(X_s, s) ] = \mathbb{E}^{y,s} \int_s^r \left[ \partial_s u(X_\tau, \tau) + \partial_y u(X_\tau, \tau) \cdot b_\tau(X_\tau) + \frac{1}{2} \partial_{yy}^2 u(X_\tau, \tau) : \sigma_\tau(X_\tau) \sigma_\tau(X_\tau)^\top \right] d\tau.\] <p>Now by definition of \(u(y, s) = \mathbb{E}[\varphi(X_t) | X_s=y]\), the left-hand side simplifies as</p> \[u(X_r, r) - u(X_s, s) = \mathbb{E}[\varphi(X_t) | X_r=X_r] - \mathbb{E}[\varphi(X_t) | X_s=X_s] = 0\] <p>and in particular its expectation is also zero. So, differentiating the above identity w.r.t. \(r\), we have</p> \[\forall s \leq r \leq t,~ \mathbb{E}^{y,s} \left[ \partial_s u(X_r, r) + \partial_y u(X_r, r) \cdot b_r(X_r) + \frac{1}{2} \partial_{yy}^2 u(X_r, r) : \sigma_r(X_r) \sigma_r(X_r)^\top \right] = 0.\] <p>In particular evaluating at \(r=s\), we have</p> \[\forall s \leq t,~ \partial_s u(y, s) + \partial_y u(y, s) \cdot b_s(y) + \frac{1}{2} \partial_{yy}^2 u(y, s) : \sigma_s(y) \sigma_s(y)^\top = 0,\] <p>which is the desired PDE \(\eqref{eq:setting:KBE}\). (There is a typo in [1, Sec. 8.3]: they do not introduce a free variable \(r \leq t\), and instead integrate the SDE followed by \(u(X_\tau, \tau)\) over all of \(\tau \in [s, t]\); then they say they differentiate w.r.t. \(t\), but here \(t\) was fixed before even defining \(u\).)</p> <p><strong>Conversely</strong>, the same calculations show that any (nice and regular enough) solution \(u(y,s)\) of \(\eqref{eq:setting:KBE}\) must be equal to \(\mathbb{E}[\varphi(X_t) | X_s=y]\). Indeed, consider the process \(u(X_\tau, \tau)\); write down the SDE that it follows by Ito’s formula; integrate it over \(\tau \in [s,t]\) and take expectations conditioned on \(X_s=y\). This yields</p> \[\mathbb{E}^{y,s}[ u(X_t, t) - u(X_s, s) ] = \mathbb{E}^{y,s} \int_s^t \left[ \partial_s u_\tau + \partial_y u_\tau \cdot b_\tau + \frac{1}{2} \partial_{yy}^2 u_\tau : \sigma_\tau \sigma_\tau^\top \right](X_\tau) d\tau = 0\] <p>since \(u\) is a solution of \(\eqref{eq:setting:KBE}\). Hence, by the final condition \({ u(\cdot, t) = \varphi(\cdot) }\),</p> <p>\(% \EE[ u(X_t, t) | X_s=y] - \EE[ u(X_s,s) | X_s=y] \mathbb{E}^{y,s}[ u(X_t, t) - u(X_s, s) ] = \mathbb{E}[\varphi(X_t) | X_s=y] - u(y,s) = 0.\)</p> </div> <h4 id="the-time-homogeneous-case">The time-homogeneous case.</h4> <p>Somewhat confusingly, in the case of an autonomous process, i.e., when \(b_t(x) = b(x)\) and \(\sigma_t(x) = \sigma(x)\) do not depend on time, there is a different but very similar-looking way to formulate the Kolmogorov Backward Equation. Fix again a \(\varphi \in C^\infty_c\) and let</p> \[\forall t \geq 0,~ \forall x \in \mathbb{R}^d,~ v(x, t) = \mathbb{E}[\varphi(X_t) | X_0 = x].\] <p>Then \(v(x,t)\) is a solution to the PDE</p> \[\label{eq:setting:KBE_homog} \partial_t v_t = \nabla v_t \cdot b + \frac{1}{2} \nabla^2 v_t : \sigma \sigma^\top ~~~~\text{with initial condition}~~~~ v(\cdot, 0) = \varphi(\cdot).\] <p>This fact follows from the Kolmogorov Backward Equation with an appropriate change of variable:</p> \[\forall 0 \leq s \leq t, \forall y \in \mathbb{R}^d,~~ v(y, t-s) = \mathbb{E}[\varphi(X_{t-s}) | X_0=y] = \mathbb{E}[\varphi(X_t) | X_s=y]\] <p>by time-homogeneity.</p> <p>The forward and backward equations are visibly connected, which is maybe not surprising since they both describe the same diffusion process. Our goal in the next section is to clarify the nature of the connection.</p> <hr> <h1 id="sec:markov">The Markov process point of view</h1> <p>To sum up: we consider a diffusion process over \(\mathbb{R}^d\) described by the SDE</p> \[\label{eq:markov:SDE} \tag{1} % dX_t = b(X_t, t) dt + \sigma(X_t, t) dW_t. dX_t = b_t(X_t) dt + \sigma_t(X_t) dW_t\] <p>and we define the associated Kolmogorov Forward resp. Backward Equations as the PDEs</p> \[\begin{align} \label{eq:markov:KFE1} \tag{$\mathrm{F}_1$} \partial_t \mu_t &amp;= -\nabla \cdot [\mu_t b_t] + \frac{1}{2} \nabla^2 : [\mu_t \sigma_t \sigma_t^\top] ~~~~\text{with initial condition}~~~~ \mu_0 \\ \label{eq:markov:KBE1} \tag{$\mathrm{B}_1$} \text{and}~~~~ -\partial_s u_s &amp;= b_s \cdot \nabla u_s + \frac{1}{2} \sigma_s \sigma_s^\top : \nabla^2 u_s \qquad ~~~~\text{with final condition}~~~~ u(\cdot, t) = \varphi(\cdot).\end{align}\] <p>We showed above that, if \(X_0 \sim \mu_0\) then \(\mu_t = \mathrm{Law}(X_t)\) is a solution of \(\eqref{eq:markov:KFE1}\), and for any fixed \(\varphi \in C^\infty_c(\mathbb{R}^d)\) and \(t &gt; 0\), \(u(y,s) = \mathbb{E}[\varphi(X_t) | X_s=y]\) is the unique solution of \(\eqref{eq:markov:KBE1}\).</p> <h4 id="the-forward-and-backward-equations-are-adjoints">The forward and backward equations are “adjoints”.</h4> <p>Let \(\mathcal{L}_t\) the linear operator from \(C^\infty_c(\mathbb{R}^d)\) to itself defined by</p> \[(\mathcal{L}_t \varphi)(x) = b_t(x) \cdot \nabla \varphi(x) + \frac{1}{2} \sigma_t(x) \sigma_t(x)^\top : \nabla^2 \varphi(x),\] <p>called the <em>infinitesimal generator</em> of the diffusion process. Let \(\mathcal{L}_t^*\) its \(L^2(\mathbb{R}^d)\) adjoint, i.e., the operator from \(\mathcal{M}(\mathbb{R}^d)\) to itself <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> such that \(\forall \varphi, \forall \mu, \int (\mathcal{L}_t \varphi) d\mu = \int \varphi d(\mathcal{L}_t^* \mu)\). By explicit computations (integration by parts) one can check it is given by</p> \[\mathcal{L}_t^* \mu = -\nabla \cdot [\mu b_t] + \frac{1}{2} \nabla^2 : [\mu \sigma_t \sigma_t^\top].\] <p>With these notations, \(\eqref{eq:markov:KFE1}\) and \(\eqref{eq:markov:KBE1}\) write respectively</p> \[\begin{align} \partial_t \mu_t &amp;= \mathcal{L}_t^* \mu_t ~~~~\text{with initial condition}~~~~ \mu_0 \\ \text{and}~~~~ -\partial_s u_s &amp;= \mathcal{L}_s u_s ~~~~\text{with final condition}~~~~ u(\cdot, t) = \varphi(\cdot).\end{align}\] <p>We have identified the sense in which the forward and backward equations are connected: their generators (in the sense of PDEs) are adjoints of each other, up to sign. But this still doesn’t tell me <em>why</em> they are connected like this... To phrase it differently, it was not clear from their interpretations as describing the evolutions of \(\mathrm{Law}(X_t)\) resp. of \(\mathbb{E}[\varphi(X_t) | X_s=y]\), that \(\eqref{eq:markov:KFE1}\) and \(\eqref{eq:markov:KBE1}\) should have adjoint generators. Next we unroll a point of view that makes it obvious that it must be the case.</p> <h4 id="the-markov-transition-kernels">The Markov transition kernels.</h4> <p>The solution \(X_t\) of \(\eqref{eq:markov:SDE}\) is a Markov process, i.e., \(\{ X_\tau\}_{\tau&gt;t}\) is independent of \(\{ X_\tau\}_{\tau&lt;t}\) conditionally on \(X_t\) for all \(t\); this can easily be checked by inspecting the definition of solutions of SDEs. Let \(\mathcal{P}^{s,t}\) the transition kernels of the Markov process \(X_t\), i.e., the operators such that</p> \[\forall s \leq t,~ \forall \varphi, \forall x,~ (\mathcal{P}^{s,t} \varphi)(x) = \mathbb{E}[\varphi(X_t) | X_s = x].\] <p>By definition their \(L^2(\mathbb{R}^d)\) adjoints are given by \(\forall \mu, \left\langle (\mathcal{P}^{s,t})^* \mu, \bullet \right\rangle = \mathbb{E}_{X_s \sim \mu} [\bullet(X_t)]\). Equivalently and perhaps more intuitively,</p> \[\forall s \leq t,~~ X_s \sim \mu_s \implies X_t \sim \mu_s \mathcal{P}^{s,t} = \mu_t\] <p>(recall that we denote indifferently \(\mu_s \mathcal{P}^{s,t}\) or \((\mathcal{P}^{s,t})^* \mu_s\)). We can also write this symbolically, in terms of probability density functions, as</p> \[\mathcal{P}^{s,t}(y, dx) = \mathbb{P}(X_t \in dx | X_s = y) = p(x,t | y,s) dx\] <p>where \(dx\) represents a small volume around \(x\), and \(\mathbb{P}\left( X_t \in B | X_s \in A \right) = \int_B dx \int_A dy~ p(x,t | y,s)\).</p> <p>With these notations, the Kolmogorov Forward and Backward Equations \(\eqref{eq:markov:KFE1}\), \(\eqref{eq:markov:KBE1}\) write</p> \[\begin{align} \text{for any fixed $s$},~ \forall t \geq s,~ ~~~~ \partial_t p(\cdot,t | y,s) &amp;= \mathcal{L}_t^* p(\cdot,t | y,s) ~~~~\text{w/ initial cond.}~~~~ p(\cdot,s | y,s) = \delta_y(\cdot), \label{eq:markov:KFE2} \tag{$\mathrm{F}_2$} \\ \text{for any fixed $t$},~ \forall s \leq t,~ ~~ -\partial_s p(x,t | \cdot,s) &amp;= \mathcal{L}_s p(x,t | \cdot,s) \quad ~~\text{w/ final cond.}~~~~ p(x,t | \cdot,t) = \delta_x(\cdot). \label{eq:markov:KBE2} \tag{$\mathrm{B}_2$} \end{align}\] <p>It takes a few minutes of focus to check that the above formulas do indeed have the same meaning as the interpretations we gave for \(\eqref{eq:markov:KFE1}\) and \(\eqref{eq:markov:KBE1}\). It is worthwhile to stop and actually check. For \(\eqref{eq:markov:KBE1}\)/\(\eqref{eq:markov:KBE2}\), it can be helpful to start by testing both sides of \(\eqref{eq:markov:KBE2}\) against some fixed \(\varphi \in C^\infty_c\) (i.e., multiply by \(\varphi(x)\) and integrate w.r.t. \(x\), for each \(s\)).</p> <p>With the above reformulations, I’m almost satisfied. Indeed <strong>the above equations are particular instances of general identities for (“regular enough”) Markov processes</strong>. It only remains to give an explanation of those general identities. For any Markov process with transition kernels \(\mathcal{P}^{s,t}\), note that by definition (of Markov processes and of the transition kernels), we have the <em>Chapman-Kolmogorov equation</em></p> \[\label{eq:markov:chapman_kolmo} \forall s \leq \tau \leq t,~ \mathcal{P}^{s,\tau} \mathcal{P}^{\tau,t} (y,dx) = \int_{\mathbb{R}^d} \mathcal{P}^{s,\tau}(y, dz) \mathcal{P}^{\tau,t}(z, dx) = \mathcal{P}^{s,t}(y,dx).\] <p>The idea is that by differentiating these identities, one obtains differential equations that characterize the Markov process. To explain this in a non-confusing way, I find it helpful to focus on the discrete-space setting.</p> <h4 id="finite-state-space-heuristic">Finite-state-space heuristic.</h4> <p>For the duration of this paragraph, pretend that the space \(\mathbb{R}^d\) is discrete and even finite. Instead of \(p(x,t | y,s)\) with \(\int_{\mathbb{R}^d} p(x,t | y,s) dx = 1\), we will write the transition probabilities \(\mathbb{P}(X_t=x | X_s=y)\) as \(p^{s,t}_{yx}\) with \(\sum_{x \in \mathbb{R}^d} p^{s,t}_{yx} = 1\). Then we can write the Chapman-Kolmogorov equation in matrix notation as</p> \[\label{eq:markov:champan_kolmo_discrete} \tag{2} \forall s \leq \tau \leq t,~~ \sum_{z \in \mathbb{R}^d} p^{s,\tau}_{yz}~ p^{\tau,t}_{zx} = p^{s,t}_{yx}, \forall y,x ~~~~\text{i.e.}~~~~ p^{s,\tau} p^{\tau,t} = p^{s,t}.\] <p>Assume the following quantities \([Q_s]_{ij}\) exist (see [1, Sec. 3.5, Eq. (3.11)-(3.12)] for sufficient conditions in terms of the \(p^{s,t}_{ij}\)):</p> \[Q_s = {\left.\frac{\partial}{\partial t} p^{s,t}\right|_{t=s}} = \lim_{h \downarrow 0} \frac{p^{s,t+h} - p^{s,t}}{h}.\] <p>The matrix \(Q_s\) is called the <em>generator</em> of the Markov jump process with transition kernels \(p^{s,t}\), and it turns out to completely characterize the Markov process. Now consider the following matrix identities, which are just rewritings of \(\eqref{eq:markov:champan_kolmo_discrete}\):</p> \[\forall s \leq t, \forall h \geq 0,~~~ \begin{cases} p^{s,t}~ p^{t,t+h} = p^{s, t+h} \\ p^{s,s+h}~ p^{s+h,t} = p^{s,t}. \end{cases}\] <p>By differentiating w.r.t. \(h\) and evaluating at \(h=0\), we obtain</p> \[\begin{cases} p^{s,t}~ Q_t = \partial_t p^{s,t} \\ Q_s~ p^{s,t} + p^{s,s} \partial_s p^{s,t} = 0 \end{cases} ~~~~~~\text{i.e.,}~~~~ \begin{cases} \partial_t p^{s,t} = p^{s,t}~ Q_t \\ -\partial_s p^{s,t} = Q_s~ p^{s,t} \end{cases}\] <p>since \(p^{s,s}_{yx} = \mathbb{1}_{y=x}\) is the identity matrix. These equations are exactly the Kolmogorov Forward and Backward Equations for Markov jump processes. <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> Note the similarity with the corresponding equations for diffusion processes \(\eqref{eq:markov:KFE2}\), \(\eqref{eq:markov:KBE2}\)!</p> <p>In this post, we started from a SDE and showed that its transition density function satisfies the PDEs with generators \(\mathcal{L}_t^*\) resp. \(-\mathcal{L}_s\); we then interpreted those equations as particular instances of the general Kolmogorov Forward and Backward Equations. One can also go in the other direction and show that a continuous Markov process with \(\mathcal{L}_t\) as the generator (in the sense of stochastic processes) can be represented by a SDE with corresponding drift \(b_t\) and diffusion \(\sigma_t\) coefficients. This alternative direction is nicely presented in [2, Chapters 6-10].</p> <hr> <p><strong>References</strong></p> <p>[1] Weinan, E., Tiejun Li, and Eric Vanden-Eijnden. <a href="https://www.ams.org/books/gsm/199/gsm199-endmatter.pdf" rel="external nofollow noopener" target="_blank"><em>Applied stochastic analysis</em></a>. Vol. 199. American Mathematical Soc., 2021.</p> <p>[2] Baldi, Paolo. <a href="https://link.springer.com/book/10.1007/978-3-319-62226-2" rel="external nofollow noopener" target="_blank"><em>Stochastic calculus</em></a>. Springer International Publishing, 2017.</p> <hr> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Again, I am being extremely loose with questions of regularity: it doesn’t make too much sense to consider \(\mathcal{L}_t\) as an operator over \(C^\infty_c(\mathbb{R}^d)\) and \(\mathcal{L}_t^*\) as an operator over \(\mathcal{M}(\mathbb{R}^d)\). The important thing is that \(\mathcal{L}_t\) morally acts on test functions, and \(\mathcal{L}_t^*\) on probability distributions. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>The Wikipedia articles on this subject are a little bit messy currently, there are three different pages titled “Kolmogorov equations”. The relevant one here is <a href="https://en.wikipedia.org/w/index.php?title=Kolmogorov_equations_(continuous-time_Markov_chains)&amp;oldid=1156787598" rel="external nofollow noopener" target="_blank">https://en.wikipedia.org/w/index.php?title=Kolmogorov_equations_(continuous-time_Markov_chains)&amp;oldid=1156787598</a>. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Guillaume Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: October 02, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1NEBMFFCE9"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1NEBMFFCE9");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>