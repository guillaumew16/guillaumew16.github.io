<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Two convergence analyses of "self"-mirror flow | Guillaume Wang </title> <meta name="author" content="Guillaume Wang"> <meta name="description" content="Machine learning theory, applied mathematics, etc. "> <meta name="keywords" content="machine learning, mathematics, optimization, optimal transport"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?aa2fd88e52df6cb3146c60000125eab2"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://guillaumew16.github.io/blog/2024/self_mirror_flow/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Guillaume</span> Wang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Research blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <link rel="stylesheet" href="/assets/css/post_custom.css?5be8581675d5ca56cf9d2d53c35cbaf6"> <div class="post"> <header class="post-header"> <h1 class="post-title">Two convergence analyses of "self"-mirror flow</h1> <p class="post-meta"> Created in October 01, 2024 by Guillaume Wang </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/category/math"> <i class="fa-solid fa-tag fa-sm"></i> math</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>The mirror descent algorithm, in its simplest form, is given by the update rule</p> \[\nabla h(x^{k+1}) = \nabla h(x^k) - \eta \nabla f(x^k),\] <p>where \(f\) is the objective function, \(\eta&gt;0\) is the step-size, and \(h\) is a hyperparameter of the algorithm called the link function, such that \(\nabla h: \mathbb{R}^d \to \mathbb{R}^d\) is bijective. The convergence analysis of mirror descent (i.e., the rate at which \(f(x^k) \to \inf f\) as \(k \to \infty\)) is a well-studied question, dating back at least to Nemirovsky and Yudin who first introduced it [1]. Sebastian Bubeck’s book has a nice summary of the results [2, Chapter 4]. In a more recent development (2017), the works [3,4] offered a fresh perspective on the question, which is the one I will use.</p> <p>In the limit where \(\eta \to 0\), the sequence \((x^k)_{k \geq 0}\) defines a continuous curve via \(x(t) = \lim_\eta x^{\lfloor{t/\eta}\rfloor}\), called the mirror flow. (This is a generalization of gradient flow, which is the continuous limit of gradient descent.) AFAIK, its first explicit appearance in the literature is the work by Amid and Warmuth [7]. The convergence analysis of mirror flow has not been written down explicitly in a research paper, but it follows easily from adapting the proofs of [4].</p> <p>The aforementioned stuff comes from the optimization literature. More or less independently, people interested in sampling and/or PDEs have been looking at the “birth-death dynamics” equation [5,6,9]</p> \[\forall i \in \{1,...,N\},~ \frac{d}{dt} \mu_t[i] = -\mu_t[i] \left( \log \frac{\mu_t[i]}{\nu[i]} - \mathsf{KL}\left( \mu_t \middle\| \nu \right) \right),\] <p>where \(\mu_t \in \Delta_N = \left\{ \mu \in \mathbb{R}_+^N, \sum_i \mu[i] = 1 \right\}\) (the probability simplex), \(\nu\) is a fixed element of \(\Delta_N\), and \(\mathsf{KL}\left( \mu \middle\| \nu \right) = \sum_j \mu[j] \log \frac{\mu_t[i]}{\nu[i]}\). <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> The KL term is there to ensure \(\mu_t\) remains normalized. As we will see, this equation can be interpreted as constrained mirror flow of \(f(\mu) = \mathsf{KL}\left( \mu \middle\| \nu \right)\), with link function \(h(\mu) = \sum_i \mu[i] \log \mu[i] = \mathsf{KL}\left( \mu \middle\| {\boldsymbol{1}} \right)\).</p> <p>If we apply the results from the optimization literature, we get the convergence guarantees</p> \[\mathsf{KL}\left( \nu \middle\| \mu_t \right) \leq e^{-t} \mathsf{KL}\left( \nu \middle\| \mu_0 \right) ~~~~\text{and}~~~~ \mathsf{KL}\left( \mu_t \middle\| \nu \right) \leq \frac{1}{e^t - 1} \mathsf{KL}\left( \nu \middle\| \mu_0 \right),\] <p>see [10] for example. I was surprised to learn that the sampling/PDE community obtained convergence guarantees of a very different form: in [9], \(\mathsf{KL}\left( \mu_t \middle\| \nu \right) \leq e^{-t} \cdot \mathrm{cst}( \min_i \frac{\mu_0[i]}{\nu[i]}, \mathsf{KL}\left( \mu_0 \middle\| \nu \right))\), and in [8], the sharper result \(\mathsf{KL}\left( \mu_t \middle\| \nu \right) = \frac{\kappa_2}{2} e^{-2t} + O(e^{-3t})\) for some constant \(\kappa_2\)—yes, this is an equality!—and even more precisely,</p> \[\label{eq:KL_expan} \tag{1} \mathsf{KL}\left( \mu_t \middle\| \nu \right) = \frac{\kappa_2}{2} e^{-2t} + \sum_{n=3}^\infty \frac{\kappa_n}{n(n-2)!} e^{-nt}\] <p>where \(\kappa_n = {\left.\frac{d^n}{dz^n}\right|_{z=0}} \log \sum_i \nu[i] \exp\left( z \log \frac{\mu_0[i]}{\nu[i]} \right)\).</p> <p>In this blog post,</p> <ul> <li> <p>I review the convergence analysis of mirror flow following [4]. The only quantitative assumption is that \(f\) is relatively strongly convex w.r.t. \(h\).</p> </li> <li> <p>I show that an expansion analogous to \(\eqref{eq:KL_expan}\) holds for any “self”-mirror flow, i.e., when \(f = h + \mathrm{linear}\).</p> </li> </ul> <p>Of course, similar things hold for the mirror descent algorithm, rather than mirror flow.</p> <p>Thanks go to Carles and Aram (the authors of [8]) for interesting discussions. They were aware of the fact that the expansion \(\eqref{eq:KL_expan}\) could be generalized to all self-mirror flows, but decided it was of limited research value; and I agree with them, but it’s the kind of fun fact that’s worth sharing.</p> <h1 id="mirror-flow-with-linear-constraint-set-definitions">Mirror flow (with linear constraint set) definitions</h1> <p>In this post, we are interested in a (constrained) optimization problem of the form</p> \[\label{eq:pb} \tag{2} \min_{x \in \mathcal{Z}} f(x)\] <p>where the constraint set \(\mathcal{Z}\) is linear, i.e., \(\mathcal{Z}= \left\{ x \in \mathbb{R}^d ; Ax = b \right\}\) for some \(A \in \mathbb{R}^{m \times d}\) and \(b \in \mathbb{R}^m\). Furthermore, we assume that we have first-order access to \(f\), as well as to \(h\) and \(h^*\) for some strictly convex “link function” \(h: \mathcal{Z}\to \mathbb{R}\). For simplicity we assume \(f\), \(h\) and \(h^*\) are \(C^3\).</p> <div class="definition" text="[7]"> <p>For an initial point \(x_0 \in \mathcal{Z}\), the Mirror Flow (MF) of \(f\) with link function \(h\) is the unique curve \((x_t)_t\) such that \(x_{t=0} = x_0\) and</p> \[\frac{dx_t}{dt} = -\Phi_{x_t}^{-1} P_{x_t} \nabla f(x_t)\] <p>where \(\Phi_x = \nabla^2 h(x)\) and \(P_x = I_d - A^\top \left[ A \Phi_x^{-1} A^\top \right]^{-1} A \Phi_x^{-1}\).</p> </div> <div class="remark"> <p>One can check that \(P_x^2 = P_x\) and \(P_x \Phi_x = \Phi_x P_x^\top\), and that \(P_x^\top\) is the orthogonal projection onto \(\mathop{\mathrm{Ker}}A\) w.r.t. the inner product \(\left\langle \cdot, \cdot \right\rangle_{\Phi_x}\). <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p> </div> <p>When analyzing the convergence of MF, the following conditions turn out to be quite natural.</p> <div class="definition" text="[4]"> <p>Let \(\mathcal{Z}\subset \mathbb{R}^d\) be a convex set, \(f, h: \mathcal{Z}\to \mathbb{R}\cup \{\infty\}\) and \(L, \mu \geq 0\). Denote by \(\mathrm{relint}(\mathcal{Z})\) the relative interior of \(\mathcal{Z}\) and by \(D_f(x, x') = f(x) - f(x') - \nabla f(x')^\top (x-x')\) the Bregman divergence of \(f\).</p> <p>\(f\) is called \(L\)-smooth relatively to \(h\) if \(\forall x, x' \in \mathrm{relint}(\mathcal{Z}), D_f(x, x') \leq L D_h(x, x')\).</p> <p>\(f\) is called \(\mu\)-strongly convex relatively to \(h\) if \(\forall x, x' \in \mathrm{relint}(\mathcal{Z}), D_f(x, x') \geq \mu D_h(x, x')\).</p> </div> <p>In this post, we are interested in the convergence of MF for \(\eqref{eq:pb}\) under the assumption of relative strong convexity:</p> <div class="assumption"> <p>\(f\) is \(\mu\)-strongly convex relatively to \(h\). Moreover, \(f\) has a unique minimizer, and we denote \(x^* = \mathop{\mathrm{arg\,min}}f\) and \(f^* = f(x^*)\). We also denote by \((x_t)_t\) a MF of \(f\) with link function \(h\).</p> </div> <div class="remark"> <p>We have \(f(x) - f^* = D_f(x, x^*)\). Indeed,</p> \[f(x) - f^* - D_f(x, x^*) = \nabla f(x^*)^\top (x - x^*) = \Big( P_{x^*} \nabla f(x^*) \Big)^\top (x - x^*) = 0.\] <p>The second equality uses that \(P_{x^*}^\top (x - x^*) = x-x^*\) since \(x-x^* \in \mathop{\mathrm{Ker}}A\), and the third equality uses that \(\Phi_{x^*}^{-1} P_{x^*} \nabla f(x^*) = 0\) since \(x^*\) is a stationary point of MF.</p> </div> <h1 id="the-classical-optimization-analysis">The classical optimization analysis</h1> <p>The following proposition establishes contraction in \(D_h(x^*, \cdot)\). It appeared as [10, Theorem 1] in the context of Fisher-Rao gradient flows (generalizations of birth-death dynamics).</p> <div class="proposition"> <p>We have \(D_h(x^*, x_t) \leq e^{-\mu t} D_h(x^*, x_0)\).</p> </div> <div class="proof"> <p>We have</p> \[\frac{d}{dt} D_h(x^*, x_t) = \nabla f(x_t)^\top (x^*-x_t) = f^* - f(x_t) - D_f(x^*, x_t) \leq -D_f(x^*, x_t) \leq -\mu D_h(x^*, x_t),\] <p>and the proposition follows by applying Grönwall’s lemma. The only non-obvious step in this string of (in)equalities is the first one, i.e., the fact that \(\frac{d}{dt} D_h(x^*, x_t) = \nabla f(x_t)^\top (x^*-x_t)\). For this, just substitute the definition and compute:</p> \[\begin{aligned} \frac{d}{dt} D_h(x^*, x_t) &amp;= \frac{d}{dt} \left[ h(x^*) - h(x_t) - \nabla h(x_t)^\top (x^*-x_t) \right] \\ &amp;= 0 - \nabla h(x_t)^\top \dot{x}_t - \nabla h(x_t)^\top (0-\dot{x}_t) - \dot{x}_t^\top \nabla^2 h(x_t) (x^* - x_t) \\ &amp;= 0 + \Big( \Phi_{x_t}^{-1} P_{x_t} \nabla f(x_t) \Big)^\top \nabla^2 h(x_t) (x^* - x_t) \\ &amp;= \nabla f(x_t)^\top P_{x_t}^\top (x^* - x_t) ~~~~ ~~\text{since}~~ \Phi_x = \nabla^2 h(x). \end{aligned}\] <p>To conclude, note that \(P_{x_t}^\top (x^* - x_t) = x^* - x_t\) since \(x^* - x_t \in \mathop{\mathrm{Ker}}A\) since \(x^*, x_t \in \mathcal{Z}\).</p> </div> <p>The above result can be deduced by taking the small-timestep limit of the original argument of [4, Theorem 3.1]; in fact by adapting more attentively the original argument, we have the following convergence in function value.</p> <div class="proposition"> <p>We have that \(t \mapsto f(x_t)\) is non-increasing and \(f(x_t) - f^* \leq \frac{\mu}{e^{\mu t}-1} % \left( D_h(x^*, x_0) - e^{\mu t} D_h(x^*, x_t) \right). D_h(x^*, x_0)\).</p> </div> <div class="remark"> <p>Observe that \(\lim_{\mu \to 0} \frac{\mu}{e^{\mu t}-1} = \big( {\left.\frac{d}{d\mu}\right|_{\mu=0}} e^{\mu t} \big)^{-1} = \frac1t\). This suggests that when \(f\) is only convex, we still have convergence of MF in function value with the rate \(1/t\). This is indeed the case, as could be shown by adapting the arguments.</p> </div> <div class="proof"> <p>By definition of MF,</p> \[\frac{d}{dt} f(x_t) = -\nabla f(x_t)^\top \Phi_{x_t}^{-1} P_{x_t} \nabla f(x_t).\] <p>Since \(P_x^2 = P_x\) and \(P_x \Phi_x = \Phi_x P_x^\top\), then \(\Phi_x^{-1} P_x = (\Phi_x^{-1} P_x) P_x = P_x^\top \Phi_x^{-1} P_x\) is symmetric positive-semidefinite. Hence \(\frac{d}{dt} f(x_t) \leq 0\).</p> <p>The previous proposition showed that</p> \[\begin{aligned} \forall s,~ \frac{d}{ds} D_h(x^*, x_s) &amp;= f^* - f(x_s) - D_f(x^*, x_s) \\ f(x_s) - f^* &amp;= -D_f(x^*, x_s) - \frac{d}{ds} D_h(x^*, x_s) \\ &amp;\leq -\mu D_h(x^*, x_s) - \frac{d}{ds} D_h(x^*, x_s) \\ &amp;= -e^{-\mu s} \frac{d}{ds} \left[ e^{\mu s} D_h(x^*, x_s) \right] \\ \text{and so}~~ \int_0^t e^{\mu s} \left( f(x_s) - f^* \right) ds &amp;\leq -\int_0^t \frac{d}{ds} \left[ e^{\mu s} D_h(x^*, x_s) \right] ds \\ &amp;= D_h(x^*, x_0) - e^{\mu t} D_h(x^*, x_t). \end{aligned}\] <p>On the other hand, since \(t \mapsto f(x_t)\) is non-increasing,</p> \[\int_0^t e^{\mu s} \left( f(x_s) - f^* \right) ds \geq \left( f(x_t) - f^* \right) \int_0^t e^{\mu s} ds = \left( f(x_t) - f^* \right) \frac1\mu (e^{\mu t}-1).\] <p>The proposition follows by combining the two inequalities above. </p> </div> <h1 id="self-mirror-flow">Self-mirror flow</h1> <p>Let us now consider the convergence behavior of MF for \(\eqref{eq:pb}\) when \(f\) is equal to \(h\) itself up to affine terms. In particular, \(D_f(x, x') = D_h(x, x')\), and so \(f\) is of course \(1\)-strongly convex relatively to \(h\). In fact we can write</p> \[f(x) = D_f(x, x^*) + f^* = D_h(x, x^*) + f^*\] <p>so we will assume w.l.o.g. that \(f = D_h(\cdot, x^*)\).</p> <p>In this case, the convergence guarantees from the classical analysis become</p> \[\frac{d}{dt} D_f(x^*, x_t) = f^* - f(x_t) - D_f(x^*, x_t) \leq -D_f(x^*, x_t)\] <p>and in particular \(D_f(x^*, x_t) \leq e^{-t} D_f(x^*, x_0)\), and</p> \[\begin{aligned} f(x_t) - f^* \leq \frac{1}{e^t-1} \int_0^t e^s \left( f(x_s) - f^* \right) ds = \frac{1}{e^t-1} \left( D_f(x^*, x_0) - e^t D_f(x^*, x_t) \right).\end{aligned}\] <p>But that still only gives us upper bounds. We actually have much better: the MF trajectory \((x_t)_t\) coincides, up to time-reparametrization, with straight lines in the dual space. This is quite intuitive in the unconstrained case, and for linear equality constraints the only potential difficulty is to properly specify what is meant by “dual”.</p> <h4 id="unconstrained-case">Unconstrained case.</h4> <p>One can check by applying the definitions the following.</p> <div class="proposition"> <p>Suppose \(\mathcal{Z}= \mathbb{R}^d\). Then MF is equivalent to</p> \[x_t = \nabla h^*(y_t) ~~\text{and}~~ \frac{dy_t}{dt} = -\nabla f(x_t)\] <p>where \(h^*\) denotes the convex conjugate of \(h\), characterized by \(\nabla h^* = (\nabla h)^{-1}\).</p> <p>Suppose furthermore that \(f(x) = D_h(x, x^*)\) for some \(x^*\), and let \(y^* = \nabla h(x^*)\). Then \(\nabla f = \nabla h - y^*\) and</p> \[\frac{dy_t}{dt} = y^* - \nabla h(x_t) = -(y_t - y^*), ~~~~\text{so}~~~~ y_t = y^* + e^{-t} (y_0 - y^*).\] </div> <h4 id="with-linear-equality-constraints">With linear equality constraints.</h4> <p>Recall that the link function \(h\) is defined as a function \(\mathcal{Z}\to \mathbb{R}\), so the notation \(\nabla h^*\) itself deserves some clarification.</p> <div class="definition"> <p>The gradient of the strictly convex and differentiable function \(h: \mathcal{Z}\to \mathbb{R}\) is the mapping \(\nabla h: \mathcal{Z}\to \mathop{\mathrm{Ker}}A\) such that</p> \[\forall v \in \mathop{\mathrm{Ker}}A,~ h(x + \varepsilon v) - h(x) = \varepsilon v^\top \nabla h(x) + o(\varepsilon).\] <p>The convex conjugate of \(h\) is the function \(h^*: \mathop{\mathrm{Ker}}A \to \mathbb{R}\) defined by \(h^*(y) = \sup_{x \in \mathcal{Z}} x^\top y - h(x)\), and \(\nabla h^*\) is defined similarly to \(\nabla h\).</p> <p>One can show that it holds \((\nabla h^*) \circ (\nabla h) = \mathop{\mathrm{id}}_{\mathcal{Z}}\) and \((\nabla h) \circ (\nabla h^*) = \mathop{\mathrm{id}}_{\mathop{\mathrm{Ker}}A}\).</p> </div> <div class="proposition"> <p>Denote by \(\Pi\) the orthogonal projector from \(\mathbb{R}^d\) onto \(\mathop{\mathrm{Ker}}A\). MF is equivalent to \(x_t = \nabla h^*(y_t)\), i.e., \(y_t = \nabla h(x_t) \in \mathop{\mathrm{Ker}}A\), and</p> \[\frac{dy_t}{dt} = -\nabla^2 h(x_t) \Phi_{x_t}^{-1} P_{x_t} \nabla f(x_t) = -P_{x_t} \nabla f(x_t) = \Pi \frac{dy_t}{dt} = -\Pi P_{x_t} \nabla f(x_t) = -\Pi \nabla f(x_t).\] <p>Suppose furthermore that \(f(x) = D_h(x, x^*)\) for some \(x^*\) and let \(y^* := \nabla h(x^*) \in \mathop{\mathrm{Ker}}A\). Then \(\nabla f = \nabla h - y^*\) and</p> \[\frac{dy_t}{dt} = -\Pi\left( \nabla h(x_t) - y^* \right) = -(y_t - y^*), ~~~~\text{so}~~~~ y_t = y^* + e^{-t} (y_0 - y^*).\] </div> <div class="proof"> <p>The first part of the proposition follows from the definition of MF and from the fact that \(\Pi P_x = \Pi (I_d - A^\top \left[ A \Phi_x^{-1} A^\top \right]^{-1} A \Phi_x^{-1}) = \Pi\), since \(A \Pi^\top = A \Pi = 0\). The rest of the proposition can be checked directly.</p> </div> <h4 id="the-expansion">The expansion.</h4> <p>Consider the unconstrained case, and suppose \(f(x) = D_h(x, x^*)\). In particular \(\nabla f = \nabla h - y^*\), or equivalently, \(\nabla f^* = \nabla h^*(\cdot + y^*)\). We have the closed-form formula, for all \(t \geq 0\),</p> \[x_t = \nabla h^*(y_t) = \nabla h^*(y^* + e^{-t} (y_0 - y^*)) = \nabla f^*(e^{-t} (y_0 - y^*)).\] <p>So let us pose \(Y = y_0 - y^*\) and, for \(\tau \in [0,1]\), \(Y_\tau = (1-\tau) Y\) and \(\tilde{x}_\tau = \nabla f^*(Y_\tau)\). Then \(\tilde{x}_0 = x_0\) and \(\tilde{x}_1 = x^*\), and by the equality case in Fenchel-Young’s inequality,</p> \[\begin{aligned} f(\tilde{x}_\tau) = f(\nabla f^*(Y_\tau)) &amp;= -f^*(Y_\tau) + Y_\tau^\top \nabla f^*(Y_\tau) \\ &amp;= -\sum_{n=0}^\infty \frac{1}{n!} \nabla^n f^*(0) : Y_\tau^{\otimes n} + Y_\tau^\top \left[ \sum_{n=0}^\infty \frac{1}{n!} \nabla^{n+1} f^*(0) \cdot Y_\tau^{\otimes n} \right]\\ &amp;= -f^*(0) + \sum_{n=1}^\infty \left[ -\frac{1}{n!} + \frac{1}{(n-1)!} \right] \nabla^n f^*(0) : Y_\tau^{\otimes n} \\ &amp;= (\inf f) + \sum_{n=2}^\infty \frac{1}{n (n-2)!} \left[ \nabla^n f^*(0) : Y^{\otimes n} \right] (1-\tau)^n.\end{aligned}\] <p>Hence, substituting \(t\) such that \(1-\tau = e^{-t}\), we have \(\tilde{x}_\tau = x_t\) and</p> \[f(x_t) - (\inf f) = \sum_{n=2}^\infty \frac{1}{n (n-2)!} \left[ \nabla^n f^*(0) : Y^{\otimes n} \right] e^{-nt}.\] <p>In the case with linear equality constraints, actually the same derivation applies verbatim. So we have proved:</p> <div class="theorem"> <p>Suppose \(f(x) = D_h(x,x^*)\) for some \(x^* \in \mathcal{Z}\). Denote by \(f^*\) the convex conjugate of \({\left.f\right|_{\mathcal{Z}}}\), defined by \(f^*(y) = \sup_{x \in \mathcal{Z}} x^\top y - f(x)\). Then</p> \[f(x_t) = \sum_{n=2}^\infty \frac{1}{n (n-2)!} \left[ {\left.\frac{d^n}{dz^n}\right|_{z=0}} f^*(zY) \right] e^{-nt} ~~~~\text{where}~~ Y = \nabla h(x_0) - \nabla h(x^*).\] </div> <h4 id="birth-death-dynamics">Birth-death dynamics.</h4> <p>To recover the result of [8], consider \(\mathcal{Z}= \Delta_N = \left\{ \mu \in \mathbb{R}_+^N; {\boldsymbol{1}}^\top \mu = 1 \right\}\) and \(f, h: \mathcal{Z}\to \mathbb{R}\) defined by \(f(\mu) = \mathsf{KL}\left( \mu \middle\| \nu \right)\) and \(h(\mu) = \mathsf{KL}\left( \mu \middle\| {\boldsymbol{1}} \right)\). One can check that MF for this \(f\) with this link function \(h\), is precisely the birth-death dynamics from the introduction.</p> <p>It is well-known that \(f(\mu) = D_h(\mu, \nu)\) and that</p> \[f^*(y) = \sup_{\mu \in \Delta_N} \sum_i \mu[i]~ y[i] - \mathsf{KL}\left( \mu \middle\| \nu \right) = \log \sum_i \nu[i]~ \exp(y[i])\] <p>(this identity is sometimes called Donsker-Varadhan duality). Moreover, \(Y[i] := \big( \nabla h(\mu_0) - \nabla h(\nu) \big)[i] = \log \frac{\mu_0[i]}{\nu[i]}\). So the theorem applied to this \(f\) and \(h\) asserts that, for \((\mu_t)_t\) following the birth-death dynamics,</p> \[f(\mu_t) = \sum_{n=2}^\infty \frac{1}{n (n-2)!} ~\underbrace{ \left[ {\left.\frac{d^n}{dz^n}\right|_{z=0}} \log \sum_i \nu[i]~ \exp\left( z \log \frac{\mu_0[i]}{\nu[i]} \right) \right] }_{\kappa_n}~ e^{-nt},\] <p>which is precisely the statement of the main result of [8].</p> <hr> <p><strong>References</strong></p> <p>[1] Arkadij Semenovič Nemirovskij and David Borisovich Yudin. “Problem complexity and method efficiency in optimization”. In: (1983).</p> <p>[2] Sébastien Bubeck. “Convex optimization: Algorithms and complexity”. In: Foundations and Trends in Machine Learning 8.3-4 (2015), pp. 231–357.</p> <p>[3] Heinz H Bauschke, Jérôme Bolte, and Marc Teboulle. “A descent lemma beyond Lipschitz gradient continuity: first-order methods revisited and applications”. In: Mathematics of Operations Research 42.2 (2017), pp. 330–348.</p> <p>[4] Haihao Lu, Robert M Freund, and Yurii Nesterov. “Relatively smooth convex optimization by first-order methods, and applications”. In: SIAM Journal on Optimization 28.1 (2018), pp. 333–354.</p> <p>[5] Yulong Lu, Jianfeng Lu, and James Nolen. “Accelerating langevin sampling with birth-death”. In: arXiv preprint arXiv:1905.09863 (2019).</p> <p>[6] Grant Rotskoff, Samy Jelassi, Joan Bruna, and Eric Vanden-Eijnden. “Global convergence of neuron birth-death dynamics”. In: International Conference on Machine Learning. 2019.</p> <p>[7] Ehsan Amid and Manfred KK Warmuth. “Reparameterizing mirror descent as gradient descent”. In: Advances in Neural Information Processing Systems 33 (2020), pp. 8430–8439.</p> <p>[8] Carles Domingo-Enrich and Aram-Alexandre Pooladian. “An explicit expansion of the Kullback-Leibler divergence along its Fisher-Rao gradient flow”. In: Transactions on Machine Learning Research (2023).</p> <p>[9] Yulong Lu, Dejan Slepčev, and Lihan Wang. “Birth–death dynamics for sampling: global convergence, approximations and their asymptotics”. In: Nonlinearity 36.11 (2023), p. 5731.</p> <p>[10] Rentian Yao, Linjun Huang, and Yun Yang. “Minimizing Convex Functionals over Space of Probability Measures via KL Divergence Gradient Flow”. In: International Conference on Artificial Intelligence and Statistics. PMLR. 2024, pp. 2530–2538.</p> <hr> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Actually people often look at a “continuous-space” version of this equation, where \((\mu_t[i])_i \in \Delta_N\) is replaced by \((\mu_t(x))_{x \in \mathbb{R}^d}\) in the space of probability <em>measures</em>, but the convergence behavior is the same except for regularity issues which can be treated separately. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>To check this, note that \(P_x A^\top = 0\) and \(\mathop{\mathrm{Ker}}P_x = \mathop{\mathrm{Im}}(I_d - P_x) \subset \mathop{\mathrm{Im}}A^\top\). <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Guillaume Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: October 02, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1NEBMFFCE9"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1NEBMFFCE9");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>