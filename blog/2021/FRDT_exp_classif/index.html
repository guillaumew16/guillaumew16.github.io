<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Regularized linear models and the Fenchel-Rockafellar duality theorem (III): Classification with the exponential loss | Guillaume Wang </title> <meta name="author" content="Guillaume Wang"> <meta name="description" content="Machine learning theory, applied mathematics, etc. "> <meta name="keywords" content="machine learning, mathematics, optimization, optimal transport"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?aa2fd88e52df6cb3146c60000125eab2"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://guillaumew16.github.io/blog/2021/FRDT_exp_classif/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Guillaume</span> Wang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Research blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <link rel="stylesheet" href="/assets/css/post_custom.css?5be8581675d5ca56cf9d2d53c35cbaf6"> <div class="post"> <header class="post-header"> <h1 class="post-title">Regularized linear models and the Fenchel-Rockafellar duality theorem (III): Classification with the exponential loss </h1> <p class="post-meta"> Created in December 15, 2021 by Guillaume Wang </p> <p class="post-tags"> <a href="/blog/2021"> <i class="fa-solid fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/category/math"> <i class="fa-solid fa-tag fa-sm"></i> math</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>This is the third of a series of posts on optimization of regularized linear models through the lens of duality. See the first one <a href="/blog/2021/FRDT_generalities">here</a> and the second one <a href="/blog/2021/FRDT_zoo_primal_dual">here</a>.</p> </blockquote> <ul id="markdown-toc"> <li> <a href="#derivation-of-the-two-variants-of-gradient-step" id="markdown-toc-derivation-of-the-two-variants-of-gradient-step">Derivation of the two variants of gradient step</a> <ul> <li><a href="#the-dual-accelerated-method" id="markdown-toc-the-dual-accelerated-method">The dual accelerated method.</a></li> </ul> </li> <li> <a href="#beyond-ell_2-algorithms-for-ell_1-regularized-classification-and-acceleration" id="markdown-toc-beyond-ell_2-algorithms-for-ell_1-regularized-classification-and-acceleration">Beyond \(\ell_2\): algorithms for \(\ell_1\)-regularized classification, and acceleration</a> <ul> <li> <a href="#fista-for-ell_1-penalized-classification" id="markdown-toc-fista-for-ell_1-penalized-classification">(F)ISTA for \(\ell_1\)-penalized classification</a> <ul> <li><a href="#primal-acceleration-fista" id="markdown-toc-primal-acceleration-fista">Primal acceleration: FISTA.</a></li> </ul> </li> <li> <a href="#adaboost-for-implicit-ell_1-regularized-classification" id="markdown-toc-adaboost-for-implicit-ell_1-regularized-classification">AdaBoost for implicit \(\ell_1\)-regularized classification</a> <ul> <li><a href="#dually-accelerated-adaboost" id="markdown-toc-dually-accelerated-adaboost">Dually accelerated AdaBoost</a></li> </ul> </li> </ul> </li> </ul> <p>We will continue with the notation from last times, in particular:</p> <ul> <li> <p>the primal problem is</p> \[\label{eq:FRDT_primal} \tag{P} \min_{w \in \mathcal{W}} \Psi(w) + \mathcal{L}(V w) =: P(w)\] </li> <li> <p>the dual problem is</p> \[\label{eq:FRDT_dual} \tag{D} \max_{a \in \mathcal{Y}^*} - \Psi^*(-V^* a) - \mathcal{L}^*(a) =: D(a).\] </li> </ul> <p>In a series of recent works, Ziwei Ji and Matus Telgarsky studied the optimization of linear models for classification with the exponential loss (and exponential-like losses), making use of duality arguments <a href="http://arxiv.org/abs/2107.00595" rel="external nofollow noopener" target="_blank">(Ji, Srebro and Telgarsky, 2021)</a>. Personally I found their derivations a bit heavy on duality black magic, so I spent a bit of time to understand what was going on. Unsurprisingly, their notion of dual variable is exactly the same as the variable \(a\) of the dual problem \(\eqref{eq:FRDT_dual}\). But it actually took me a while to realize that, for a relatively subtle reason.</p> <p>In this section, we adopt some of the notation from Ziwei Ji and Matus Telgarsky’s papers, on top of the generic ones already used so far.</p> <ul> <li> <p>Let \(\ell(u) = \exp(u)\) be the exponential loss.</p> </li> <li> <p>We may assume WLOG that \(y^{\text{tgt}}_i = -1\) for all \(i\), since we may transform the dataset \((\phi(x_i), y^{\text{tgt}}_i)_i\) into the equivalent dataset \((z_i, -1)_i\) with \(z_i = -y^{\text{tgt}}_i \phi(x_i)\). So the data-fitting term \(\mathcal{L}(y) = \sum_i \ell(-y^{\text{tgt}}_i y_i)\), is simply \(\mathcal{L}(y) = \sum_i \ell(y_i)\).</p> </li> <li> <p>The (unnormalized) empirical risk of a parameter \(w\) is defined as \(\mathcal{R}(w) = \sum_{i=1}^n \ell(\left\langle w, z_i \right\rangle)\).</p> </li> </ul> <p>For classification tasks, it is common to consider as data-fitting term</p> \[\mathcal{L}(y) = \sum_{i=1}^n \ell(y_i).\] <p>A common trick when analyzing learning algorithms for classification, is that \(\ell\) is a strictly increasing function so that we may use a different choice for the data-fitting term: \(\widetilde{\mathcal{L}}= (\ell^{-1}) \circ \mathcal{L}\), i.e</p> \[\widetilde{\mathcal{L}}(y) = \ell^{-1} \left( \sum_{i=1}^n \ell(y_i) \right).\] <p>Plus, for \(\ell = \exp\), \(\widetilde{\mathcal{L}}\) is just the log-sum-exp function \(\widetilde{\mathcal{L}}(y) = \log \sum_{i=1}^n e^{y_i}\), which is convex. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p> <p>It turns out that those two seemingly equivalent choices lead to slightly different optimization algorithms, with significantly different convergence speeds <a href="https://arxiv.org/abs/1906.04540" rel="external nofollow noopener" target="_blank">(Ji and Telgarsky, 2020)</a>.</p> <ol> <li> <p>Associated with the choice of \(\mathcal{L}\) is the vanilla gradient step</p> \[w_{t+1} = w_t - \eta_t \nabla \mathcal{R}(w).\] </li> <li> <p>Associated with the choice of \(\widetilde{\mathcal{L}}\) is the normalized gradient step</p> \[w_{t+1} = w_t - \eta_t \frac{\nabla \mathcal{R}(w)}{\mathcal{R}(w)}.\] </li> </ol> <h2 id="derivation-of-the-two-variants-of-gradient-step">Derivation of the two variants of gradient step</h2> <p>Let a convex regularizer \(\Psi(w)\). Let us naively write down the update rules from for the saddle-point formulation of the optimization problems \(\min_w \Psi(w) + \mathcal{L}(Vw)\) and \(\min_w \Psi(w) + \widetilde{\mathcal{L}}(Vw)\). Note that:</p> <ul> <li> <p>Since \(\mathcal{L}(Vw) = \mathcal{R}(w)\),</p> \[\partial_w \mathcal{L}(Vw) = V^* \partial \mathcal{L}(Vw) = \nabla \mathcal{R}(w).\] </li> <li> <p>Since \(\ell^{-1}(v) = \log(v)\) and so \(\widetilde{\mathcal{L}}= \log \circ \mathcal{L}\),</p> \[\partial_w \widetilde{\mathcal{L}}(Vw) = V^* \partial \widetilde{\mathcal{L}}(Vw) = \frac{\nabla \mathcal{R}(w)}{\mathcal{R}(w)}.\] </li> </ul> <p>Now consider using the scheme from with gradient descent steps for \(w_{t+1}\) and fully-optimizing for \(a_{t+1}\). We get the update rule</p> \[w_{t+1} = w_t - \eta_t \left[ \partial \Psi(w_t) + V^* a_t \right] = w_t - \eta_t V^* \partial \mathcal{L}(Vw) - \eta_t \partial \Psi(w_t)\] <p>and similarly with \(\widetilde{\mathcal{L}}\). Plugging in the values of \(V^* \partial \mathcal{L}(Vw)\) and \(V^* \partial \widetilde{\mathcal{L}}(Vw)\), we see that we get almost exactly the vanilla and basic gradient steps from above; the only difference is that we get an extra term \(- \eta_t \partial \Psi(w_t)\). When \(\Psi = \frac{\lambda}{2} \left\lVert \cdot \right\rVert_2^2\), then as discussed in , a cheap heuristic for implicit regularization (i.e \(\lambda \to 0\)) is to simply remove that extra term.</p> <p>It looks like we didn’t do anything else than write down the classical primal gradient descent steps on the unregularized losses \(\mathcal{L}(Vw)\) and \(\widetilde{\mathcal{L}}(Vw)\). That is true. The advantage of invoking the dual space in this context is that it allows a finer convergence analysis than if we only stay in the primal <a href="https://arxiv.org/abs/1906.04540" rel="external nofollow noopener" target="_blank">(Ji and Telgarsky, 2020)</a>. It also leads naturally to a dual accelerated method, discussed next, that would otherwise appear as utter magic. It might even allow to divinate yet other funky update rules, by using other choices for the dual update, or by replacing the exponential by some other surrogate loss.</p> <h4 id="the-dual-accelerated-method">The dual accelerated method.</h4> <p>In <a href="http://arxiv.org/abs/2107.00595" rel="external nofollow noopener" target="_blank">(Ji, Srebro and Telgarsky, 2021)</a>, they propose a dual-accelerated method for the same problem (Algorithm 1 of the paper). To present it would require a discussion of accelerated mirror descent, which would take us a bit far. Let us only say that their method is essentially just a variant of what we called the “fully dual approach” <a href="/blog/2021/FRDT_zoo_primal_dual#duality-gap-formulation-and-fully-dual-approach-the-frank-wolfe-algorithm">last time</a>, with mirror descent replaced by a form of accelerated mirror descent.</p> <p>Interestingly, their new method can also be interpreted as an instance of the general mix-and-match scheme of , with what seems to be an unusual form of accelerated gradient descent for \(w_{t+1}\). However this point of view is not the one they used to derive and analyze their method. I find it interesting, and pretty confusing, that a method derived by acceleration in the dual can be interpreted as a primal-dual method with acceleration in the primal.</p> <h2 id="beyond-ell_2-algorithms-for-ell_1-regularized-classification-and-acceleration">Beyond \(\ell_2\): algorithms for \(\ell_1\)-regularized classification, and acceleration</h2> <h3 id="fista-for-ell_1-penalized-classification">(F)ISTA for \(\ell_1\)-penalized classification</h3> <p>Consider the same optimization problem as before: \(\min_w \Psi(w) + \widetilde{\mathcal{L}}(Vw)\), this time with the choice of regularizer \(\Psi(w) = \lambda \left\lVert w \right\rVert_1\). Consider using the scheme from with fully-optimizing for \(a_{t+1}\) and proximal gradient descent for \(w_{t+1}\). We get the update rule</p> \[\begin{aligned} a_{t+1} &amp;= \nabla \widetilde{\mathcal{L}}(Vw_t) \\ w_{t+1} &amp;= \mathop{\mathrm{prox}}_{\tau \Psi}(w_t - \tau V^* a_{t+1})\end{aligned}\] <p>Since \(\Psi = \lambda \left\lVert w \right\rVert_1\), this is simply the ISTA algorithm applied to \(\widetilde{\mathcal{L}}(Vw)\). <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup></p> <h4 id="primal-acceleration-fista">Primal acceleration: FISTA.</h4> <p>Accelerated proximal gradient descent in the primal.</p> \[\begin{aligned} a_{t+1} &amp;= \nabla \widetilde{\mathcal{L}}(V \overline{\gamma}_t) \\ w_{t+1} &amp;= \mathop{\mathrm{prox}}_{\tau \Psi} \left( \overline{\gamma}_t - \tau V^* a_{t+1} \right) \\ \overline{\gamma}_{t+1} &amp;= w_{t+1} + \theta (w_{t+1} - w_t)\end{aligned}\] <p>which reduces to</p> \[\begin{aligned} w_{t+1} &amp;= \mathop{\mathrm{prox}}_{\tau \Psi} \left( \overline{\gamma}_t - \tau \left.\nabla_w \widetilde{\mathcal{L}}(V w)\right|_{\overline{\gamma}_t} \right) \\ \overline{\gamma}_{t+1} &amp;= w_{t+1} + \theta (w_{t+1} - w_t)\end{aligned}\] <p>Notice that there is another way to accelerate, by updating \(w_{t+1}\) starting from \(w_t\) instead of \(\overline{\gamma}_t\):</p> \[\begin{aligned} a_{t+1} &amp;= \nabla \widetilde{\mathcal{L}}(V \overline{\gamma}_t) \\ w_{t+1} &amp;= \mathop{\mathrm{prox}}_{\tau \Psi} \left( w_t - \tau V^* a_{t+1} \right) \\ \overline{\gamma}_{t+1} &amp;= w_{t+1} + \theta (w_{t+1} - w_t)\end{aligned}\] <p>which reduces to \(\begin{aligned} w_{t+1} &amp;= \mathop{\mathrm{prox}}_{\tau \Psi} \left( w_t - \tau \left.\nabla_w \widetilde{\mathcal{L}}(V w)\right|_{\overline{\gamma}_t} \right) \\ \overline{\gamma}_{t+1} &amp;= w_{t+1} + \theta (w_{t+1} - w_t)\end{aligned}\)</p> <p>This method can be viewed as the Chambolle-Pock algorithm with \(\sigma = +\infty\).</p> <h3 id="adaboost-for-implicit-ell_1-regularized-classification">AdaBoost for implicit \(\ell_1\)-regularized classification</h3> <p>It is well-known that AdaBoost results in \(\ell_1\)-margin maximization <a href="https://arxiv.org/abs/2105.02083" rel="external nofollow noopener" target="_blank">(Chinot, Kuchelmeister, Löffler and van de Geer, 2021)</a>. In this paragraph, we heuristically recover that fact, by interpreting AdaBoost as (almost) an instance of an algorithm previously derived in the framework of FRDT.</p> <p>We consider AdaBoost as stated in Algorithm 1 of <a href="https://arxiv.org/abs/2105.02083" rel="external nofollow noopener" target="_blank">(Chinot, Kuchelmeister, Löffler and van de Geer, 2021)</a>. <sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup> With our notation, one can check that the algorithm can be formulated as:</p> \[\begin{aligned} w_0 &amp;= 0 \\ a_t &amp;= \nabla \widetilde{\mathcal{L}}(V w_t) \\ u_t &amp;= \left\lVert V^* a_t \right\rVert_\infty \partial \left\lVert \cdot \right\rVert_\infty(-V^* a_t) = \partial \frac{1}{2} \left\lVert \cdot \right\rVert_\infty^2 (-V^* a_t) = \partial \left( \frac{1}{2} \left\lVert \cdot \right\rVert_1^2 \right)^* (-V^* a_t) \\ w_{t+1} &amp;= w_t + \eta u_t\end{aligned}\] <p>Denote \(\varphi: \left[ \mathbb{R}\to \mathbb{R}, x \mapsto \frac{x^2}{2} \right]\) and \(\psi(w) = \varphi(\left\lVert w \right\rVert_1)\). In the above algorithm, the equation for \(u_t\) can be written as \(u_t = \partial \psi^*(-V^* a_t)\), and more generally we have that for even and convex \(\varphi\) <sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup></p> \[\begin{gathered} \psi^* = \varphi^* \circ \left\lVert \cdot \right\rVert_\infty, \\ u_t = \partial \psi^*(-V^* a_t) = (\varphi^*)'(\left\lVert -V^* a_t \right\rVert_\infty)~ \partial \left\lVert \cdot \right\rVert_\infty(-V^* a_t).\end{gathered}\] <p>So by using different choices for the scalar mapping \(\varphi\), we obtain different choices for the adaptive stepsize. We may expect AdaBoost to have similar regularization behavior for all of them.</p> <p>Note that AdaBoost is thus strongly reminiscent of the Frank-Wolfe-like method obtained by what we called the “fully dual approach” <a href="/blog/2021/FRDT_zoo_primal_dual#duality-gap-formulation-and-fully-dual-approach-the-frank-wolfe-algorithm">last time</a>:</p> \[\begin{aligned} w_0, a_0 &amp; ~\text{such that}~ a_0 \in \partial \widetilde{\mathcal{L}}(Vw_0) \\ a_t &amp;= \nabla \widetilde{\mathcal{L}}(V w_t) \\ w_{t+1} &amp;= (1-\eta) w_t + \eta \frac{1}{\lambda} \nabla \psi^*(-V^* a_t)\end{aligned}\] <p>with \(\lambda \to 0\). The only difference is that AdaBoost updates \(w_{t+1}\) from \(w_t\) and \(u_t\) via an additive step instead of a convex combination. However since \(\lambda \to 0\), the update \(\eta \frac{1}{\lambda} \nabla\psi^*(-V^* a_t)\) can be expected to have large magnitude so that the \(-\eta w_t\) term makes no big difference anyway.</p> <h4 id="dually-accelerated-adaboost">Dually accelerated AdaBoost</h4> <p>Armed with the above almost-interpretation of AdaBoost as a previously derived method, we may derive an accelerated version of AdaBoost. This would require a discussion of accelerated mirror descent, which would take us a bit far. Let us only point out that all the necessary ingredients are contained in Appendix B of <a href="http://arxiv.org/abs/2107.00595" rel="external nofollow noopener" target="_blank">(Ji, Srebro and Telgarsky, 2021)</a>. Namely, I think the only adaptation needed is to replace \(-V^* a_t\) (\(-Z^\top q_t\) in their notation) by \(u_t = \partial \psi^*(-V^* a_t)\) everywhere in their Algorithm 1.</p> <p>In fact, I expect that deriving and obtaining guarantees for fast \(\ell_1\)-margin maximization is a very straightforward task, by making the appropriate adaptations in the proofs of that paper.</p> <hr> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Beyond the exponential loss, the same trick can be applied for other choices of surrogate loss \(\ell\). A crucial condition for the trick is that \(\widetilde{\mathcal{L}}\) must be convex; additional desirable conditions are described in Assumption 1.2 of <a href="https://arxiv.org/abs/1906.04540" rel="external nofollow noopener" target="_blank">(Ji and Telgarsky, 2020)</a>, where they also give sufficient conditions in their Lemma 5.2. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>The subtlety that confused me for a while, is that choosing \(\mathcal{L}\) vs. \(\widetilde{\mathcal{L}}\) as the data-fitting term leads to different notions of dual variable, \(a = \nabla \mathcal{L}(Vw)\) vs. \(\tilde{a}= \nabla \widetilde{\mathcal{L}}(Vw) = (\ell^{-1})'(\mathcal{L}(Vw))~ a\). I initially only had the choice of \(\mathcal{L}\) in mind, so as I stared at the derivations of <a href="https://arxiv.org/abs/1906.04540" rel="external nofollow noopener" target="_blank">(Ji and Telgarsky, 2020)</a>, I could not understand why they considered renormalizing the stepsize by \((\ell^{-1})'(\mathcal{L}(Vw_t))\) in the dual. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:3" role="doc-endnote"> <p><a href="https://blogs.princeton.edu/imabandit/2013/04/11/orf523-ista-and-fista/" rel="external nofollow noopener" target="_blank">https://blogs.princeton.edu/imabandit/2013/04/11/orf523-ista-and-fista/</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:4" role="doc-endnote"> <p>Our discussion extends immediately to a number of variants of AdaBoost: logistic instead of exponential loss, and various choices of adaptive stepsize (see the paragraph just below Algorithm 1 in <a href="https://arxiv.org/abs/2105.02083" rel="external nofollow noopener" target="_blank">(Chinot, Kuchelmeister, Löffler and van de Geer, 2021)</a>). <a href="#fnref:4" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:5" role="doc-endnote"> <p>See Example 13.8 in the book <em>Convex Analysis and Monotone Operator Theory in Hilbert Spaces</em> by Bauschke and Combettes, 2017. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Guillaume Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: October 26, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1NEBMFFCE9"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1NEBMFFCE9");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>